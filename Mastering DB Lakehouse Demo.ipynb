{"cells":[{"cell_type":"markdown","source":["This code is used for examples related to the Mastering Databricks lake house platform. To use it, you need to have a table schema and sample data, which are provided separately. You can set up the sample data on an Azure SQL instance that Databricks can access, either on a public or private IP or domain. You also need to create a storage account, preferably ADLS Gen2, to store the output data. Finally, you need to change the connection parameters accordingly to make this example work."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"306e4777-83b8-453f-b6b7-363471b8fe47","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\n//Check if SQL server JDBC driver is available\nClass.forName(\"com.microsoft.sqlserver.jdbc.SQLServerDriver\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b485edba-6264-49d3-92d1-53d45086d0ce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n//Setup database connection string\nval jdbcHostname = \"your SQL Server Database IP or Host Name\"\nval jdbcPort = 1433\nval jdbcDatabase = \"Database Name\"\n// Create the JDBC URL without passing in the user and password parameters.\nval jdbcUrl = s\"jdbc:sqlserver://${jdbcHostname}:${jdbcPort};database=${jdbcDatabase}\"\n// Create a Properties() object to hold the parameters.\nimport java.util.Properties\nval connectionProperties = new Properties()\nconnectionProperties.put(\"user\", s\"datbaseuserid\")\nconnectionProperties.put(\"password\", s\"databsepassword\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cc68c789-4ce4-45d6-8533-5f42dc1250e9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n//Set the connection properties\nval driverClass = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\nconnectionProperties.setProperty(\"Driver\", driverClass)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5cb38c7c-878b-4b0b-9c99-b1dbe176367a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n//Load the exam_data in the Exam_Data_From_SQLServer_DB variable\nval ExamdataFromSQLDB = spark.read.jdbc(jdbcUrl, \"oltpstore\", connectionProperties)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"746e076c-6793-450a-a19d-d2f897c2e10d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n//Convert the Exam_Data_From_SQLServer_DB to DataFrames for processing\nval ExamDataInDF = ExamdataFromSQLDB.toDF()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"957048d7-7979-4951-84d1-d98448330adc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n// Apply filter to select exam results from all the courses\nval FilterdExamResultsInDF = ExamDataInDF.filter($\"jsonobjecttype\" === \"CertificateRequest\").select($\"jsondata\")\nFilterdExamResultsInDF.createOrReplaceTempView(\"resultjson\")\ndisplay(FilterdExamResultsInDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f74e9ad8-129f-4212-b69a-f592f85cda5d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nimport org.apache.spark.sql.hive.HiveContext\nval sqlContext = new HiveContext(sc)\nval resultjsonfilterd = sqlContext.sql(\"SELECT from_json(jsondata,'EventID string,OrganizationGuid string,TeamID string, UserId string,emailId string,Marks int,TotalMarks int,completiondate Date,passstate string') FROM resultjson\") \nval resultstore = resultjsonfilterd.select(\"from_json(jsondata).*\")\ndisplay(resultstore)\nresultstore.createOrReplaceTempView(\"resultstore\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9891da6a-2fcb-42bb-a2c3-30d78e266762","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nimport org.apache.spark.sql.hive.HiveContext\n// sc - existing spark context\nval sqlContext = new HiveContext(sc)\nval dfiltered = sqlContext.sql(\"select from_json(jsondata,'UserId string,emailId string,Marks int,TotalMarks int,completiondate string,passstate int') FROM oltpstore\") \n//select(explode($\"employees\"))\n//df.select(col(\"name.*\")\nval flattenDF = dfiltered.select(\"from_json(jsondata).*\")\n//val df2Flatten = flattenDF.toDF(\"UserId\",\"emailId\",\"Marks\",\"TotalMarks\",\"completiondate\",\"passstate\")\n  // df2Flatten.printSchema()\n//df2Flatten.show()\ndisplay(flattenDF)\ndfiltered.createOrReplaceTempView(\"oltpstore1\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b6921283-9f67-4628-ae45-a1f92a215726","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["adlsAccountName = \"dbstodfsdfsdf\"\nadlsContainerName = \"dbdsdssd\"\nadlsFolderName = \"RAW\"\nmountPoint = \"/mnt/raw\"\n \n# Application (Client) ID\n#applicationId = dbutils.secrets.get(scope=\"aks001sdgs1\",key=\"ClientId\")\n applicationId = \"0b57c728-198d-479857897-997699-07d10\";\n# Application (Client) Secret Key\n#authenticationKey = dbutils.secrets.get(scope=\"akv-07011\",key=\"ClientSecret\")\n authenticationKey =\"\"\n# Directory (Tenant) ID\ntenandId = dbutils.secrets.get(scope=\"aks001sdgs1\",key=\"TenantId\")\n \nendpoint = \"https://login.microsoftonline.com/\" + tenandId + \"/oauth2/token\"\nsource = \"abfss://\" + adlsContainerName + \"@\" + adlsAccountName + \".dfs.core.windows.net/\" + adlsFolderName\n \n# Connecting using Service Principal secrets and OAuth\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n           \"fs.azure.account.oauth2.client.id\": applicationId,\n           \"fs.azure.account.oauth2.client.secret\": authenticationKey,\n           \"fs.azure.account.oauth2.client.endpoint\": endpoint}\n \n# Mount ADLS Storage to DBFS only if the directory is not already mounted\nif not any(mount.mountPoint == mountPoint for mount in dbutils.fs.mounts()):\n  dbutils.fs.mount(\n    source = source,\n    mount_point = mountPoint,\n    extra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dee9c712-71b0-48b1-bba7-0fdf6913e22a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\nspark.conf.set(\n  \"fs.azure.account.key.dbstoragegen2mc4u.dfs.core.windows.net\", \"DIt5jItsdgsdgsdgsda92q4sdgsd-jPaDerO-sdgsdgsdg5/A==\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4e14e102-4d8d-444c-a56a-85e1a6598d8c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"fs.azure.createRemoteFileSystemDuringInitialization\", \"true\")\ndbutils.fs.ls(\"abfss://newconatinerdsg4dgu@dbsgtordfsdu.dfs.core.windows.net/\")\nspark.conf.set(\"fs.azure.createRemoteFileSystemDuringInitialization\", \"false\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"93dd3618-f5de-41b3-8654-af0021ce2058","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\ndbutils.fs.ls(\"abfss://dbdemo@dbstoragesdgsu.dfs.core.windows.net/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1c7303c7-7ba1-497d-8e6f-34793f9e9e29","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n\nresultstore.printSchema()\n\nresultstore.write.mode(SaveMode.Overwrite)\n.option(\"header\",\"true\")\n.csv(\"abfss://dbdemo@dbstoragegsdgdg.dfs.core.windows.net/RAW/resultstore.csv\")\nresultstore.write.mode(SaveMode.Overwrite)\n.option(\"header\",\"true\")\n.parquet(\"abfss://dbdemo@dbstoragegesddsg.dfs.core.windows.net/RAW/resultstore.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fbee40f1-9f54-4051-b102-72dcda7bd95c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql drop TABLE parquetresultstore"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f224bf2f-4eea-4b00-a158-376f5e077021","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n%sql \nCREATE TABLE parquetresultstore\nUSING parquet\nOPTIONS (path \"abfss://dbdemo@dbstoragegedsgsg.dfs.core.windows.net/RAW/resultstore.parquet\")\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5578c770-2343-4a5d-8163-0c3d26bc3413","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.sql('select * from  parquetresultstore') \n\ndf.write.format(\"delta\").mode('overwrite').option(\"overwriteSchema\", \"true\").save(\"abfss://dbdemo@dbstoragesdgsgs.dfs.core.windows.net/RAW/parquetresultstore.delta\") \n\nspark.sql(\"CREATE TABLE IF NOT EXISTS deltaresultstore USING DELTA LOCATION 'abfss://dbdemo@dbstoragesdgsdg.dfs.core.windows.net/RAW/parquetresultstore.delta'\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"56751cc8-a05e-4886-bffc-7c0d7e4bca2c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nselect * from deltaresultstore where passstate = \"1\" and userid !=\"null\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a2430eef-94ab-480a-b5a1-66fc6b22a94d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Mastering DB Lakehouse Demo","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2418450431047595}},"nbformat":4,"nbformat_minor":0}
